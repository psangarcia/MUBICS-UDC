{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificadores\n",
    "\n",
    "OpenCV implementa un subconjunto de algoritmos de aprendizaje máquina que nos pueden ayudar a realizar una serie de tareas de análisis de datos. Otras librerías de python, como scikit-learn disponen de un conjunto más amplio de algoritmos de clasificación, regresión y clustering.\n",
    "\n",
    "La resolución de un problema de clasificación consta de una fase de aprendizaje en la que el clasificador es entrenado con un conjunto de ejemplos de entrada y sus correspondientes etiquetas o salidas. Idealmente se dispone de otro conjunto de ejemplos de entradas y salidas para validar la calidad del entrenamiento realizado.\n",
    "\n",
    "Por tanto, el paso previo a utilizar un clasificador es construir nuestro conjunto de entrenamiento. En una situación real, el conjunto de entrenamiento vendrá determinado por los vectores de características calculados a partir de la imagen y por el etiquetado manual realizado sobre dichas imágenes.\n",
    "\n",
    "En los siguientes ejemplos utilizaremos un conjunto de entrenamiento que incluye la propia librería. El conjunto de entrenamiento está formado por 20000 vectores de características calculados a partir de imágenes con letras. La primera columna de cada fila es un caracter que representa lo que aparece en la imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19]\n",
      " [ 8]\n",
      " [ 3]\n",
      " ...\n",
      " [19]\n",
      " [18]\n",
      " [ 0]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Leer el fichero con los ejemplos y convertir las etiquetas\n",
    "# que aparecen en la primera columna a números\n",
    "data = np.loadtxt('res/letter-recognition.data', \n",
    "                    dtype='float32', \n",
    "                    delimiter = ',',\n",
    "                    converters= {0: lambda ch: ord(ch)-ord('A')})\n",
    "\n",
    "labels = data[:,0] # Primera columna: etiquetas\n",
    "#print(labels)\n",
    "# Se crea un array unidimensional que es necesario convertir a bidimensional\n",
    "labels = labels.reshape((data.shape[0], 1)).astype(np.int32) \n",
    "print(labels)\n",
    "#data = data[:,1:] # Restantes columnas: vectores de caracteristicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## División del conjunto de entrenamiento\n",
    "\n",
    "Necesitamos evaluar la calidad del entrenamiento en un conjunto de datos que no haya sido usado para entrenar. Si tenemos suficientes ejemplos, la forma más sencilla de obtener nuestro conjunto de test es reservar un subconjunto de ejemplos del conjunto de entrenamiento, preferiblemente de forma aleatoria.\n",
    "\n",
    "Una forma aún mejor de evaluar la calidad del entrenamiento es utilizar validación cruzada. Si existe un número suficiente de ejemplos de cada clase, podemos usar K-fold y si tenemos pocos ejemplos, mejor optar por un método Leave-one-out.\n",
    "\n",
    "Una forma de generar de forma aleatoria bloques de ejemplos para entrenamiento y test usando una kfold es la siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000,) [15189 19928 14200 ...  9504 13308 14918]\n",
      "0 test (2000,) [15189 19928 14200 ...  9573 18495   871]\n",
      "0 train (18000,) [11185  2251 11343 ...  9504 13308 14918]\n",
      "1 test (2000,) [11185  2251 11343 ...  4600 16996 16993]\n",
      "1 train (18000,) [15189 19928 14200 ...  9504 13308 14918]\n",
      "2 test (2000,) [ 5378  3462  2955 ...   376 17634  4583]\n",
      "2 train (18000,) [15189 19928 14200 ...  9504 13308 14918]\n",
      "3 test (2000,) [15985 19664  7076 ... 11361 15276 15391]\n",
      "3 train (18000,) [15189 19928 14200 ...  9504 13308 14918]\n",
      "4 test (2000,) [ 2456 15087 14360 ...  5410  9838 13118]\n",
      "4 train (18000,) [15189 19928 14200 ...  9504 13308 14918]\n",
      "5 test (2000,) [ 4799 14876 18225 ...    24 17229  3099]\n",
      "5 train (18000,) [15189 19928 14200 ...  9504 13308 14918]\n",
      "6 test (2000,) [ 7512 11616 14783 ...  2009  2244  6747]\n",
      "6 train (18000,) [15189 19928 14200 ...  9504 13308 14918]\n",
      "7 test (2000,) [17609 14532  2926 ...  9835  8914  2065]\n",
      "7 train (18000,) [15189 19928 14200 ...  9504 13308 14918]\n",
      "8 test (2000,) [19842  5320  4763 ...  7777 13480 10031]\n",
      "8 train (18000,) [15189 19928 14200 ...  9504 13308 14918]\n",
      "9 test (2000,) [16331  5569 14027 ...  9504 13308 14918]\n",
      "9 train (18000,) [15189 19928 14200 ...  7777 13480 10031]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(0, data.shape[0]) # Todos los indices del vector\n",
    "np.random.shuffle(indices) # Aleatorizar los indices del vector\n",
    "print(indices.shape, indices)\n",
    "\n",
    "k = 10 # k de la k-fold\n",
    "step = int(data.shape[0] / k) # Numero de ejemplos usados en cada fold (2000)\n",
    "\n",
    "# En cada iteracion de la k-fold seleccionaremos un bloque distinto de\n",
    "# indices para el conjunto de test y los k-1 restantes para \n",
    "# entrenamiento:\n",
    "# Iteracion 1: T E E E E E E E E E \n",
    "# Iteracion 2: E T E E E E E E E E \n",
    "# Iteracion 3: E E T E E E E E E E \n",
    "# ...\n",
    "# Iteracion 10: E E E E E E E E E T \n",
    "\n",
    "for i in range(k):\n",
    "    # Indices para test\n",
    "    test_idx = indices[i*step:(i+1)*step]\n",
    "    print(i, \"test\", test_idx.shape, test_idx)\n",
    "    \n",
    "    # Indices para entrenamiento    \n",
    "    train_idx_a = indices[:i*step] \n",
    "    train_idx_b = indices[(i+1)*step:]\n",
    "    train_idx = np.concatenate([train_idx_a, train_idx_b])\n",
    "    print(i, \"train\", train_idx.shape, train_idx)\n",
    "    \n",
    "    # Obtener el conjunto de entrenamiento a partir de los índices\n",
    "    train_data_k = data[train_idx]\n",
    "    train_labels_k = labels[train_idx]\n",
    "\n",
    "    # Obtener el conjunto de test a partir de los índices\n",
    "    test_data_k = data[test_idx]\n",
    "    test_labels_k = labels[test_idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors\n",
    "\n",
    "La función `cv2.ml.KNearest_create` es la implementación de OpenCV del algoritmo K-Nearest Neigbors. No necesita ningún parámetro y devuelve un objeto clasificador.\n",
    "\n",
    "El objeto clasificador contiene el método `train` que permite entrenar el clasificador. Este método recibe los siguientes parámetros:\n",
    "- Matriz con los ejemplos de entrenamiento\n",
    "- Disposición de los ejemplos en la matriz (por filas o por columnas)\n",
    "- Matriz con las etiquetas de los ejemplos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dividimos el conjunto original de entrenamiento en entrenamiento y test\n",
    "\n",
    "train_data = data[:18000,:]\n",
    "train_labels = labels[:18000,:]\n",
    "test_data = data[-2000:,:]\n",
    "test_labels = labels[-2000:,:]\n",
    "\n",
    "# Creamos el clasificador\n",
    "knn = cv2.ml.KNearest_create()\n",
    "# Entrenamos el clasificador\n",
    "knn.train(train_data, cv2.ml.ROW_SAMPLE, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez el clasificador ha sido entrenado es posible utilizarlo para predecir nuevos ejemplos. Para ello se utiliza la función `findNearest`, que recibe dos parámetros: los ejemplos a predecir y el número de vecinos más cercanos que se considerarán para obtener el resultado de la clasificación. Esta función tiene cuatro parámetros de salida:\n",
    "- `ret`: Clase del primer elemento del vector (sólo es útil si predecimos un único ejemplo).\n",
    "- `results`: Matriz en la que cada fila contiene las predicciones del ejemplo correspondiente\n",
    "- `neighbours`: Matriz en el que se muestran los k vecinos más cercanos del ejemplo a predecir\n",
    "- `dist`: Distancia de cada uno de los k vecinos al ejemplo a predecir.\n",
    "\n",
    "En este caso vamos a utilizar esta función con los ejemplos del conjunto de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Ejemplo 0 -----\n",
      "Clase seleccionada [15.]\n",
      "Vecinos mas proximos [15. 15. 15.]\n",
      "Distancia a vecinos [ 7. 11. 13.]\n",
      "Etiqueta real [15]\n",
      "---- Ejemplo 1 -----\n",
      "Clase seleccionada [12.]\n",
      "Vecinos mas proximos [12. 12. 12.]\n",
      "Distancia a vecinos [3. 3. 4.]\n",
      "Etiqueta real [12]\n",
      "---- Ejemplo 2 -----\n",
      "Clase seleccionada [21.]\n",
      "Vecinos mas proximos [21. 21. 21.]\n",
      "Distancia a vecinos [5. 6. 8.]\n",
      "Etiqueta real [21]\n"
     ]
    }
   ],
   "source": [
    "# Validamos el clasificador con el conjunto de test\n",
    "ret, results, neighbours, dist = knn.findNearest(test_data, 3)\n",
    "# Comprobamos resultados para los tres primeros ejemplos del conjunto de test\n",
    "for i in range(3):\n",
    "    print(\"---- Ejemplo\", i, \"-----\")\n",
    "    print(\"Clase seleccionada\", results[i])\n",
    "    print(\"Vecinos mas proximos\", neighbours[i])\n",
    "    print(\"Distancia a vecinos\", dist[i])\n",
    "    print(\"Etiqueta real\", test_labels[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando realizamos un entrenamiento es interesante conocer el porcentaje de aciertos obtenido en el conjunto de test, el cual nos ofrece una idea aproximada de cómo funcionará nuestro clasificador en un sistema real.\n",
    "\n",
    "Una forma de calcular los aciertos es la siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aciertos 1904 / 2000 95.2 %\n"
     ]
    }
   ],
   "source": [
    "# Comprobación de los resultados en el conjunto de test\n",
    "# Aciertos => todos aquellos ejemplos en los que el vecino más\n",
    "# cercano coincide con la etiqueta establecida\n",
    "success = np.sum(results == test_labels)\n",
    "\n",
    "print(\"Aciertos\", success, \"/\", test_labels.shape[0], 100*float(success)/float(test_labels.shape[0]), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio\n",
    "Entrena un clasificador K-Nearest Neigbors con el conjunto de entrenamiento de ejemplo utilizando una K-fold con k =10 y calcula el promedio de acierto en los k conjuntos de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Ejemplo 0 -----\n",
      "Clase seleccionada [0.]\n",
      "Vecinos mas proximos [0. 0. 0.]\n",
      "Distancia a vecinos [4. 6. 6.]\n",
      "Etiqueta real [0]\n",
      "---- Ejemplo 1 -----\n",
      "Clase seleccionada [21.]\n",
      "Vecinos mas proximos [21. 21. 21.]\n",
      "Distancia a vecinos [0. 0. 3.]\n",
      "Etiqueta real [21]\n",
      "---- Ejemplo 2 -----\n",
      "Clase seleccionada [15.]\n",
      "Vecinos mas proximos [15. 15. 15.]\n",
      "Distancia a vecinos [ 7. 10. 11.]\n",
      "Etiqueta real [15]\n",
      "Aciertos en los k conjuntos de test 1922 / 2000 96.1 %\n"
     ]
    }
   ],
   "source": [
    "# Se toma como punto de partida la creación y entrenamiento del clasificador con el conjunto de entrenamiento bajo una K-fold con k=10:\n",
    "\n",
    "# Creación del clasificador\n",
    "knn = cv2.ml.KNearest_create()\n",
    "\n",
    "# Entrenamiento del clasificador\n",
    "knn.train(train_data_k, cv2.ml.ROW_SAMPLE, train_labels_k)\n",
    "\n",
    "# Se valida el clasificador con el conjunto de test estableciendo 3 vecinos más cercanos considerados:\n",
    "ret, results, neighbours, dist = knn.findNearest(test_data_k, 3)\n",
    "\n",
    "# Al igual que en el ejemplo mostrado, se proporcionan los resultados para los tres primeros ejemplos del conjunto de test:\n",
    "for i in range(3):\n",
    "    print(\"---- Ejemplo\", i, \"-----\")\n",
    "    print(\"Clase seleccionada\", results[i])\n",
    "    print(\"Vecinos mas proximos\", neighbours[i])\n",
    "    print(\"Distancia a vecinos\", dist[i])\n",
    "    print(\"Etiqueta real\", test_labels_k[i])\n",
    "\n",
    "# Se procede al cálculo de promedio de acierto en los k conjuntos de test:\n",
    "success = np.sum(results == test_labels_k)\n",
    "print(\"Aciertos en los k conjuntos de test\", success, \"/\", test_labels_k.shape[0], 100*float(success)/float(test_labels_k.shape[0]), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Trees\n",
    "\n",
    "La función `cv2.RTrees_create` permite crear un clasificador de tipo Random Trees. El formato de la función de entrenamiento `train` es exactamente el mismo que en K-Nearest Neighbors. Sin embargo, la función para predecir las clases es `predict`, que toma como único parámetro la matriz con los ejemplos de predicción. Esta función devuelve dos salidas:\n",
    "- `ret`: Clase del primer elemento del vector (sólo es útil si predecimos un único ejemplo).\n",
    "- `results`: Matriz en la que cada fila contiene las predicciones del ejemplo correspondiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aciertos 1870 / 2000 93.5 %\n"
     ]
    }
   ],
   "source": [
    "rt = cv2.ml.RTrees_create()\n",
    "rt.setMaxDepth(100)\n",
    "\n",
    "rt.train(train_data, cv2.ml.ROW_SAMPLE, train_labels)\n",
    "ret, results = rt.predict(test_data)\n",
    "\n",
    "success = np.sum(results == test_labels)\n",
    "\n",
    "print(\"Aciertos\", success, \"/\", test_labels.shape[0],100*float(success)/float(test_labels.shape[0]), \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio\n",
    "Entrena un clasificador Random Forest con el conjunto de entrenamiento de ejemplo utilizando una K-fold con k=10 y calcula el promedio de acierto en los k conjuntos de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aciertos de rt2 en los k conjuntos de test 1891 / 2000 94.55 %\n"
     ]
    }
   ],
   "source": [
    "# Se crea el clasificador Random Forest con denominación rt2:\n",
    "rt2 = cv2.ml.RTrees_create()\n",
    "rt2.setMaxDepth(100)\n",
    "\n",
    "# Entrenamiento del clasificador:\n",
    "rt2.train(train_data_k, cv2.ml.ROW_SAMPLE, train_labels_k)\n",
    "ret2, results2 = rt2.predict(test_data_k)\n",
    "\n",
    "# Cálculo del promedio de acierto en los k conjuntos de test:\n",
    "success2 = np.sum(results2 == test_labels_k)\n",
    "\n",
    "print(\"Aciertos de rt2 en los k conjuntos de test\", success2, \"/\", test_labels_k.shape[0],100*float(success2)/float(test_labels_k.shape[0]), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n",
    "La función `cv2.SVM_create` sirve para crear un clasificador de tipo SVM. El formato de las funciones `train` y `predict` es exactamente el mismo que en Random Forest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aciertos 1024 / 2000 51.2 %\n"
     ]
    }
   ],
   "source": [
    "svm = cv2.ml.SVM_create()\n",
    "svm.train(train_data, cv2.ml.ROW_SAMPLE, train_labels)\n",
    "ret, results = svm.predict(test_data)\n",
    "\n",
    "success = np.sum(results == test_labels)\n",
    "\n",
    "print(\"Aciertos\", success, \"/\", test_labels.shape[0], 100*float(success)/float(test_labels.shape[0]), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El entrenamiento se realiza utilizando los parámetros por defecto pero no siempre estos parámetros obtienen los mejores resultados de clasificación. Probar distintos parámetros puede ser una labor tediosa por lo que OpenCV cuenta con un método que entrena el algoritmo con distintos parámetros y devuelve el objeto entrenado con los parámetros óptimos. Este método utiliza una k-fold internamente durante la optimización. Nota: puede tardar varios minutos en ejecutarse la operación!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.trainAuto(train_data, cv2.ml.ROW_SAMPLE, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio\n",
    "Calcula el porcentaje de acierto en el conjunto de test con el svm entrenado optimizando parámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aciertos con el clasificador svm con parámetros optimizados 1966 / 2000 98.3 %\n"
     ]
    }
   ],
   "source": [
    "# Se crea el clasificador de tipo svm con denominación \"svm_ejercicio\" y parámetros optimizados:\n",
    "svm_ejercicio = cv2.ml.SVM_create()\n",
    "svm_ejercicio.trainAuto(train_data_k, cv2.ml.ROW_SAMPLE, train_labels_k)\n",
    "ret_ejercicio, results_ejercicio = svm_ejercicio.predict(test_data_k)\n",
    "\n",
    "# Cálculo del procentaje de acierto:\n",
    "success_ejercicio = np.sum(results_ejercicio == test_labels_k)\n",
    "print(\"Aciertos con el clasificador svm con parámetros optimizados\", success_ejercicio, \"/\", test_labels_k.shape[0], 100*float(success_ejercicio)/float(test_labels_k.shape[0]), \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardar y cargar clasificadores\n",
    "Cuando trabajamos en un problema real en un problema que requiera un clasificador, el modo de operación habitual es entrenar uno o varios clasificadores con validación cruzada y tratando de optimizar parámetros para obtener las tasas de acierto más elevadas. El mejor clasificador será el que se utilice para tareas de predicción.\n",
    "\n",
    "Para evitar reentrenar el clasificador cada vez que se necesite realizar una predicción, el clasificador se puede salvar a un fichero y cargarlo cuando sea necesario utilizarlo. Para ello, todos los objetos creados con `XXXX_create` disponen de los métodos `save` y `load`. Ambos métodos toman como parámetro el nombre del fichero donde se almacenará o desde el que se cargará el clasificador. El método `load` devuelve además el clasificador entrenado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_ejercicio.save('svm-trained-characters.xml')\n",
    "\n",
    "svm2 = cv2.ml.SVM_create()\n",
    "svm2 = svm2.load('svm-trained-characters.xml')\n",
    "\n",
    "\n",
    "rt.save('rt-trained-characters.xml')\n",
    "\n",
    "rt2 = cv2.ml.RTrees_create()\n",
    "rt2 = rt2.load('rt-trained-characters.xml')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
